{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summarize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         feature_1    feature_2    feature_3    feature_4\n",
      "count  6000.000000  6000.000000  6000.000000  6000.000000\n",
      "mean      7.990044     5.175071     9.982420    31.074333\n",
      "std       8.002022     3.770585    10.200213    14.588738\n",
      "min       0.000556     0.034444     0.502000     1.000000\n",
      "25%       1.508611     1.531111     3.352750    16.000000\n",
      "50%       5.027917     4.742500     6.563500    37.000000\n",
      "75%      10.893819     8.357222    13.073750    43.000000\n",
      "max      23.999444    23.838333    77.700000    52.000000\n",
      "        feature_1   feature_2   feature_3   feature_4\n",
      "count  800.000000  800.000000  800.000000  800.000000\n",
      "mean    10.133354    4.858312    9.544297   29.768750\n",
      "std      8.999654    3.644326   10.092338    8.211246\n",
      "min      0.004722    0.111944    0.526000   12.000000\n",
      "25%      2.022569    1.603819    2.379750   23.000000\n",
      "50%      7.044444    4.086944    6.087500   28.000000\n",
      "75%     22.153333    7.907361   12.688000   36.000000\n",
      "max     23.999722   23.621944   57.748000   44.000000\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "# summary of the train data\n",
    "print(train_df[['feature_1', 'feature_2', 'feature_3', 'feature_4']].describe())\n",
    "# summary of the test data\n",
    "print(test_df[['feature_1', 'feature_2', 'feature_3', 'feature_4']].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. kick out the outliers that is not in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>label</th>\n",
       "      <th>example_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2410.000000</td>\n",
       "      <td>2410.000000</td>\n",
       "      <td>2410.000000</td>\n",
       "      <td>2410.000000</td>\n",
       "      <td>2410.000000</td>\n",
       "      <td>2410.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.166595</td>\n",
       "      <td>5.521854</td>\n",
       "      <td>10.091701</td>\n",
       "      <td>30.687552</td>\n",
       "      <td>0.723651</td>\n",
       "      <td>2996.648548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.361535</td>\n",
       "      <td>3.678301</td>\n",
       "      <td>10.136648</td>\n",
       "      <td>8.592227</td>\n",
       "      <td>0.447284</td>\n",
       "      <td>1741.025460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.102778</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.323125</td>\n",
       "      <td>1.959722</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1503.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.875833</td>\n",
       "      <td>5.449028</td>\n",
       "      <td>6.575500</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2987.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.376458</td>\n",
       "      <td>8.593750</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4523.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.997778</td>\n",
       "      <td>22.632778</td>\n",
       "      <td>77.700000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5996.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_1    feature_2    feature_3    feature_4        label  \\\n",
       "count  2410.000000  2410.000000  2410.000000  2410.000000  2410.000000   \n",
       "mean      8.166595     5.521854    10.091701    30.687552     0.723651   \n",
       "std       8.361535     3.678301    10.136648     8.592227     0.447284   \n",
       "min       0.000556     0.102778     0.521000    15.000000     0.000000   \n",
       "25%       1.323125     1.959722     3.660000    21.000000     0.000000   \n",
       "50%       4.875833     5.449028     6.575500    34.000000     1.000000   \n",
       "75%      11.376458     8.593750    13.330000    38.000000     1.000000   \n",
       "max      23.997778    22.632778    77.700000    40.000000     1.000000   \n",
       "\n",
       "        example_id  \n",
       "count  2410.000000  \n",
       "mean   2996.648548  \n",
       "std    1741.025460  \n",
       "min       0.000000  \n",
       "25%    1503.500000  \n",
       "50%    2987.500000  \n",
       "75%    4523.750000  \n",
       "max    5996.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[train_df['feature_4'].between(15, 40)]\n",
    "# train_df = train_df[train_df['feature_3'].between(0.5, 58)]\n",
    "train_df = train_df[train_df['feature_2'].between(0.1, 23)]\n",
    "\n",
    "train_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalize both train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['feature_1'] = (train_df['feature_1']-train_df['feature_1'].min())/train_df['feature_1'].max()\n",
    "# train_df['feature_2'] = (train_df['feature_2']-train_df['feature_2'].min())/train_df['feature_2'].max()\n",
    "# train_df['feature_3'] = (train_df['feature_3']-train_df['feature_3'].min())/train_df['feature_3'].max()\n",
    "# train_df['feature_4'] = (train_df['feature_4']-train_df['feature_4'].min())/train_df['feature_4'].max()\n",
    "train_df['feature_1'] = train_df['feature_1']/train_df['feature_1'].max()\n",
    "train_df['feature_2'] = train_df['feature_2']/train_df['feature_2'].max()\n",
    "train_df['feature_3'] = train_df['feature_3']/train_df['feature_3'].max()\n",
    "train_df['feature_4'] = train_df['feature_4']/train_df['feature_4'].max()\n",
    "\n",
    "# test_df['feature_1'] = (test_df['feature_1']-test_df['feature_1'].min())/test_df['feature_1'].max()\n",
    "# test_df['feature_2'] = (test_df['feature_2']-test_df['feature_2'].min())/test_df['feature_2'].max()\n",
    "# test_df['feature_3'] = (test_df['feature_3']-test_df['feature_3'].min())/test_df['feature_3'].max()\n",
    "# test_df['feature_4'] = (test_df['feature_4']-test_df['feature_4'].min())/test_df['feature_4'].max()\n",
    "test_df['feature_1'] = test_df['feature_1']/test_df['feature_1'].max()\n",
    "test_df['feature_2'] = test_df['feature_2']/test_df['feature_2'].max()\n",
    "test_df['feature_3'] = test_df['feature_3']/test_df['feature_3'].max()\n",
    "test_df['feature_4'] = test_df['feature_4']/test_df['feature_4'].max()\n",
    "\n",
    "# to numpy array\n",
    "train_data = train_df.values\n",
    "test_data = test_df.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. train validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=1)\n",
    "X_train = train_data[:, :4]\n",
    "y_train = train_data[:, 4]\n",
    "X_val = val_data[:, :4]\n",
    "y_val = val_data[:, 4]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "model_1 = svm.SVC(kernel='linear', probability=True)\n",
    "model_1.fit(X_train, y_train)\n",
    "yhat = model_1.predict(X_val)\n",
    "acc = accuracy_score(y_val, yhat)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the trained model to predict the test data\n",
    "X_test = test_data[:, :4]\n",
    "yhat = model_1.predict(X_test)\n",
    "\n",
    "# save the result\n",
    "result = pd.DataFrame({'example_id': test_data[:, 4].astype(int), 'prediction': yhat.astype(int)})\n",
    "result.to_csv('SVM.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now train multiple models and ensemble them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train_data, tol=1e-3, C=1.0, max_iter=1000, kernel='linear', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, random_state=None):\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "    X_train = train_data[:, :4];    y_train = train_data[:, 4]\n",
    "    X_val = val_data[:, :4];        y_val = val_data[:, 4]\n",
    "    model = svm.SVC(kernel=kernel, tol=tol, C=C, max_iter=max_iter, degree=degree, gamma=gamma, coef0=coef0, shrinking=shrinking, probability=probability, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    yhat = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, yhat)\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    return model\n",
    "\n",
    "# train KNN\n",
    "\n",
    "def train_knn(train_data, n_neighbors, weights):\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
    "    X_train = train_data[:, :4];    y_train = train_data[:, 4]\n",
    "    X_val = val_data[:, :4];        y_val = val_data[:, 4]\n",
    "    model = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    model.fit(X_train,y_train)\n",
    "    yhat = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, yhat)\n",
    "    print('Accuracy: %.3f' % acc)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.990\n",
      "Accuracy: 0.984\n",
      "Accuracy: 0.964\n",
      "Accuracy: 0.979\n",
      "Accuracy: 0.974\n",
      "Accuracy: 0.982\n",
      "Accuracy: 0.961\n",
      "Accuracy: 0.966\n",
      "Accuracy: 0.990\n",
      "Accuracy: 0.979\n",
      "Accuracy: 0.979\n",
      "Accuracy: 0.959\n",
      "Accuracy: 0.977\n",
      "Accuracy: 0.977\n",
      "Accuracy: 0.979\n",
      "Accuracy: 0.990\n",
      "Accuracy: 0.982\n",
      "Accuracy: 0.979\n",
      "Accuracy: 0.977\n",
      "Accuracy: 0.984\n",
      "Accuracy: 0.984\n",
      "Accuracy: 0.987\n",
      "Accuracy: 0.966\n",
      "Accuracy: 0.990\n",
      "Accuracy: 0.990\n",
      "Accuracy: 0.979\n",
      "Accuracy: 0.966\n",
      "Accuracy: 0.959\n",
      "Accuracy: 0.990\n",
      "Accuracy: 0.982\n",
      "Accuracy: 0.982\n",
      "Accuracy: 0.961\n",
      "Accuracy: 0.977\n",
      "Accuracy: 0.974\n",
      "Accuracy: 0.982\n",
      "Accuracy: 0.979\n",
      "Accuracy: 0.961\n",
      "Accuracy: 0.964\n",
      "Accuracy: 0.977\n",
      "Accuracy: 0.987\n",
      "Accuracy: 0.977\n",
      "Accuracy: 0.992\n",
      "Accuracy: 0.979\n",
      "Accuracy: 0.990\n",
      "Accuracy: 0.977\n",
      "Accuracy: 0.982\n",
      "Accuracy: 0.969\n",
      "Accuracy: 0.966\n",
      "Accuracy: 0.982\n",
      "Accuracy: 0.984\n",
      "Accuracy: 0.979\n",
      "Accuracy: 0.969\n",
      "Accuracy: 0.966\n",
      "Accuracy: 0.969\n",
      "Accuracy: 0.966\n",
      "Accuracy: 0.990\n",
      "Accuracy: 0.977\n",
      "Accuracy: 0.972\n",
      "Accuracy: 0.984\n",
      "Accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "\n",
    "for tol in [1e-2, 1e-3, 1e-4]:\n",
    "    for c in [0.5, 0.6, 0.8, 1]:\n",
    "        model_list.append(train_svm(train_data, tol=tol, C=c, kernel='linear'))\n",
    "        model_list.append(train_svm(train_data, tol=tol, C=c, kernel='poly'))\n",
    "        model_list.append(train_svm(train_data, tol=tol, C=c, kernel='poly', degree=2))\n",
    "        model_list.append(train_svm(train_data, tol=tol, C=c, kernel='rbf'))\n",
    "        model_list.append(train_svm(train_data, tol=tol, C=c, kernel='sigmoid'))\n",
    "\n",
    "# for n in [4,5,6]:\n",
    "#     for weights in ['uniform', 'distance']:\n",
    "#         model_list.append(train_knn(train_data, n, weights))\n",
    "\n",
    "\n",
    "# model_2 = train_svm(train_data, tol=1e-3, C=1.0, max_iter=1000, kernel='linear', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, random_state=None)\n",
    "# model_3 = train_svm(train_data, tol=1e-3, C=1.0, max_iter=1000, kernel='poly', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, random_state=None)\n",
    "# model_4 = train_svm(train_data, tol=1e-3, C=1.0, max_iter=1000, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, random_state=None)\n",
    "# model_5 = train_svm(train_data, tol=1e-3, C=1.0, max_iter=1000, kernel='sigmoid', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, random_state=None)\n",
    "\n",
    "# model_list = [model_1, model_2, model_3, model_4, model_5]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data[:, :4]\n",
    "y_list = []\n",
    "for model in model_list:\n",
    "    yhat = model.predict(X_test)\n",
    "    y_list.append(yhat)\n",
    "\n",
    "y_list = np.array(y_list)\n",
    "y_list = y_list.T\n",
    "y_list = y_list.tolist()\n",
    "\n",
    "yhat = []\n",
    "for y in y_list:\n",
    "    # vote\n",
    "    yhat.append( int(max(set(y), key=y.count)) )\n",
    "\n",
    "# save the result\n",
    "result = pd.DataFrame({'example_id': test_data[:, 4].astype(int), 'prediction': yhat})\n",
    "result.to_csv('SVM_ensemble2.csv', index=False)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a5152ad0efa82a444bbb7b5b09330ae1eae37d6d488966c94b24f2df6242daa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
